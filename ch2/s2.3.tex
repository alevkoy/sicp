\documentclass{article}
\author{Abraham Levkoy}
\title{SICP exercises, section 2.3}

\usepackage{mystyle}

\begin{document}
\maketitle

\section{Exercise 2.53}
\begin{quote}
    What would the interpreter print in response to evaluating each of the
    following expressions?
\end{quote}

\begin{lstlisting}
(list 'a 'b 'c)
> (a b c)
(list (list 'george))
> ((george))
(cdr '((x1 x2) (y1 y2)))
> ((y1 y2))
(cadr '((x1 x2) (y1 y2)))
> (y1 y2)
(pair? (car '(a short list)))
> #f
(memq 'red '((red shoes) (blue socks)))
> #f
(memq 'red '(red shoes blue socks))
> #t
\end{lstlisting}

\section{Exercise 2.54}
\begin{quote}
    Two lists are said to be \texttt{equal?} if they contain equal elements
    arranged in the same order. For example,

    \begin{lstlisting}
(equal? '(this is a list)
        '(this is a list))
    \end{lstlisting}

is true, but

    \begin{lstlisting}
(equal? '(this is a list)
        '(this (is a) list))
    \end{lstlisting}

    is false. To be more precise, we can define \texttt{equal?} recursively in
    terms of the basic \texttt{eq?} equality of symbols by saying that
    \texttt{a} and \texttt{b} are \texttt{equal?} if they are both symbols and
    the symbols are \texttt{eq?}, or if they are both lists such that
    \texttt{(car a)} is \texttt{equal?} to \texttt{(car b)} and \texttt{(cdr
    a)} is \texttt{equal?} to \texttt{(cdr b)}. Using this idea, implement
    \texttt{equal?} as a procedure.
\end{quote}

\lstinputlisting[firstline=3,lastline=9]{ch2/ex2.54.scm}

\section{Exercise 2.55}
\begin{quote}
    Eva Lu Ator types to the interpreter the expression

    \begin{lstlisting}
(car ''abracadabra)
    \end{lstlisting}

    To her surprise, the interpreter prints back \texttt{quote}. Explain.
\end{quote}

The character \texttt{'} is a syntactic shorthand for using the special form
\texttt{quote} with the following object as the argument. It evaluates to a
list of the symbols in the argument. When it is used on itself, as here, the
inner \texttt{quote} gets evaluated by the outer \texttt{quote}, producing a
list with \texttt{quote} as its first element, i.e.
\begin{lstlisting}
(quote abracadabra)
\end{lstlisting}
\texttt{car} then evaluates to the first element of its argument.

\section{Exercise 2.56}
\begin{quote}
    Show how to extend the basic differentiator to handle more kinds of
    expressions. For instance, implement the differentiation rule
    $$\frac{d(u^n)}{dx} = nu^{n-1}\frac{du}{dx}$$
    by adding a new clause to the \texttt{deriv} program and defining
    appropriate procedures \texttt{exponentiation?}, \texttt{base},
    \texttt{exponent}, and \texttt{make-exponentiation}. (You may use the
    symbol \texttt{**} to denote exponentiation.) Build in the rules that
    anything raised to the power 0 is 1 and anything raised to the power 1 is
    the thing itself.
\end{quote}

\lstinputlisting[firstline=47,lastline=60]{ch2/ex2.56.scm}
\lstinputlisting[firstline=63,lastline=87]{ch2/ex2.56.scm}

\section{Exercise 2.57}
\begin{quote}
    Extend the differentiation program to handle sums and products of arbitrary
    numbers of (two or more) terms. Then the last example above could be
    expressed as
    \begin{lstlisting}
(deriv '(* x y (+ x 3)) 'x)
    \end{lstlisting}
    Try to do this by changing only the representation for sums and products,
    without changing the \texttt{deriv} procedure at all. For example, the
    \texttt{addend} of a sum would be the first term, and the \texttt{augend}
    would be the sum of the rest of the terms.
\end{quote}

The new representation of sums and products is a list with the operator in the
first position and the terms in subsequent positions. The only things that needs
to change are the selectors for the second operands:
\lstinputlisting[firstline=111,lastline=123]{ch2/ex2.56.scm}

\section{Exericse 2.58}
\begin{quote}
    Suppose we want to modify the differentiation program so that it works with
    ordinary mathematical notation, in which \texttt{+} and \texttt{*} are
    infix rather than prefix operators. Since the differentiation program is
    defined in terms of abstract data, we can modify it to work with different
    representations of expressions solely by changing the predicates,
    selectors, and constructors that define the representation of the algebraic
    expressions on which the differentiator is to operate.
    \begin{enumerate}
        \item Show how to do this in order to differentiate algebraic
            expressions presented in infix form, such as \texttt{(x + (3 * (x +
            (y + 2))))}. To simplify the task, assume that \texttt{+} and
            \texttt{*} always take two arguments and that expressions are fully
            parenthesized.
        \item The problem becomes substantially harder if we allow standard
            algebraic notation, such as \texttt{(x + 3 * (x + y + 2))}, which
            drops unnecessary parentheses and assumes that multiplication is
            done before addition. Can you design appropriate predicates,
            selectors, and constructors for this notation such that our
            derivative program still works?
    \end{enumerate}
\end{quote}

\begin{enumerate}
    \item In fully parenthesized infix form, the only things that need to
        change are the constructors and selectors for the different types of
        expressions.
        \lstinputlisting[firstline=147,lastline=200]{ch2/ex2.56.scm}
    \item Using standard algebraic notation, the predicates identifying the
        different types of expressions need to employ a notion of precedence.
        An expression is only of the type indicated by a certain operator if no
        lower-precedence operators are present. The selectors are modified to
        search for the operand relevant to their type and split the overall
        expression around that operator. The constructors stay the same as in
        part 1, which can result in output expressions that are not reduced to
        the simplest form, but that would be considerably more complicated.
        \lstinputlisting[firstline=211,lastline=288]{ch2/ex2.56.scm}
\end{enumerate}

\section{Exercise 2.59}
\begin{quote}
    Implement the \texttt{union-set} operation for the unordered-list
    representation of sets.
\end{quote}

\lstinputlisting[firstline=24,lastline=29]{ch2/ex2.59.scm}

This is the same approach as \texttt{intersection-set}, \texttt{car}-ing down
\texttt{set1} and \texttt{cons}-ing up \texttt{set2}. This has the disadvantage
that, each time we search in \texttt{set2} for an element from \texttt{set1},
we needlessly consider all of the elements that we have already added from
\texttt{set1}. If \texttt{set1} has size $M$, and \texttt{set2} has size $N$,
this produces a worst-case (sets totally disjoint) runtime complexity of
\begin{equation*}
    O(M * N + \sum_{i=1}^{M}i = O(M * N + \frac{M^2}{2}) = O(M^2 + MN).
\end{equation*}

An alternative strategy would be to store the non-intersecting elements of
\texttt{set1} in a third set, \texttt{set3} then append \texttt{set2} to that
set. This would only pay the cost of traversing the non-intersecting elements
once:
\begin{equation*}
    O(M * N + M) = O(M *N)
\end{equation*}

If $M \approx N$, these asymptotic complexities are the same. Consequently, it
does not seem worth the additional code complexity to optimize this algorithm,
especially considering the inefficiency of the underlying data structure. There
are lower-hanging fruit here.

\section{Exercise 2.60}
\begin{quote}
    We specified that a set would be represented as a list with no duplicates.
    Now suppose we allow duplicates. For instance, the set ${1,2,3}$ could
    be represented as the list \texttt{(2 3 2 1 3 2 2)}. Design procedures
    \texttt{element-of-set?}, \texttt{adjoin-set}, \texttt{union-set}, and
    \texttt{intersection-set} that operate
    on this representation. How does the efficiency of each compare with the
    corresponding procedure for the non-duplicate representation? Are there
    applications for which you would use this representation in preference to
    the non-duplicate one?
\end{quote}

\texttt{element-of-set?} and \texttt{intersection-set} remain the same. Because
sets do not need to be deduplicated, \texttt{adjoin-set} and \texttt{union-set}
can be simplified.

\lstinputlisting[firstline=9,lastline=10]{ch2/ex2.60.scm}
\lstinputlisting[firstline=22,lastline=23]{ch2/ex2.60.scm}

The time complexity of \texttt{element-of-set?} remains $O(N)$, but $N$ is now
the sizes of the list representing \texttt{set}, not the numbers of distinct
elements in \texttt{set}. Likewise, the complexity of \texttt{intersection-set}
is still $O(NM)$, but $N$ and $M$ are now the size of the lists representing
\texttt{set1} and \texttt{set2}, not the number of distinct elements in those
sets.

\texttt{adjoin-set} now has time complexity $O(1)$, as compared to $O(N)$, and
\texttt{union-set} has time complexity $O(N+M)$ (referring to the sizes of the
representations), as compared to $O(M^2 + MN)$ (referring to the numbers of
distinct elements in the sets).

The sets themselves now take up more memory than in the previous representation.
The memory cost varies according to the degree of duplication in the sets.

This representation would be preferable to the deduplicated representation if
\texttt{adjoin-set} and \texttt{union-set} operations were frequent, and
\texttt{element-of-set?} and \texttt{intersection-set} operations were
infrequent, assuming that memory is plentiful enough to easily accomodate the
expected degree of duplication. It would also be preferable in most scenarios
where the average degree of duplication was expected to be low. In terms of
asymptotic complexity, the representation allowing duplicates would be more
efficient as long as the number of duplicates in a typical set was
$O(\textrm{number of distinct elements})$.

\section{Exercise 2.61}
\begin{quote}
    Give an implementation of \texttt{adjoin-set} using the ordered
    representation. By analogy with \texttt{element-of-set?} show how to take
    advantage of the ordering to produce a procedure that requires on the
    average about half as many steps as with the unordered representation.
\end{quote}

\lstinputlisting[firstline=25,lastline=35]{ch2/ex2.61.scm}

This version does use $O(N)$ stack space, unlike the previous version, but it
is already returning an $N$-size list, so the space complexity doesn't change.

\section{Exercise 2.62}
\begin{quote}
    Give a $\Theta(n)$ implementation of \texttt{union-set} for sets
    represented as ordered lists.
\end{quote}

This follows the same general form as \texttt{intersection-set}.
\lstinputlisting[firstline=57,lastline=71]{ch2/ex2.61.scm}

\section{Exercise 2.63}
\begin{quote}
    Each of the following two procedures converts a binary tree to a list.

    \begin{lstlisting}
(define (tree->list-1 tree)
  (if (null? tree)
      '()
      (append
       (tree->list-1
        (left-branch tree))
       (cons (entry tree)
             (tree->list-1
              (right-branch tree))))))

(define (tree->list-2 tree)
  (define (copy-to-list tree result-list)
    (if (null? tree)
        result-list
        (copy-to-list
         (left-branch tree)
         (cons (entry tree)
               (copy-to-list
                (right-branch tree)
                result-list)))))
  (copy-to-list tree '()))
    \end{lstlisting}

    \begin{enumerate}
        \item Do the two procedures produce the same result for every tree? If
            not, how do the results differ? What lists do the two procedures
            produce for the trees in Figure 2.16?
        \item Do the two procedures have the same order of growth in the number
            of steps required to convert a balanced tree with $n$ elements to a
            list? If not, which one grows more slowly?
    \end{enumerate}
\end{quote}

\begin{enumerate}
    \item Both procedures have the effect of outputting the in-order traversal
        of the input tree. Consequently, they produce the same result for every
        tree. For all of the lists in Figure 2.16, both procedures
        produce the list \texttt{(1 3 5 7 9)}.
    \item Both procedures traverse each element of the tree once.
        \texttt{tree->list-2} just performs a constant-time \texttt{cons}
        operation for each element, so \texttt{tree->list-2} has $O(n)$ time
        complexity.

        \texttt{tree->list-1} performs an \texttt{append} for each
        tree element. \texttt{Append} has time complexity linear in the number
        of elements in the first argument, which is the list form of the left
        branch of the current element. Because the tree is balanced, each
        recursive invocation of \texttt{tree->list-1} calls \texttt{append} with
        a list approximately half as long as in the previous invocation of
        \texttt{tree->list-1}. Therefore, the time complexity of
        \texttt{tree->list-1} is $O(n\log n)$.

        The number of steps for \texttt{tree->list-2} grows more slowly than for
        \texttt{tree->list-1}.
\end{enumerate}

\section{Exericse 2.64}
\begin{quote}
    The following procedure \texttt{list->tree} converts an ordered list to a
    balanced binary tree. The helper procedure \texttt{partial-tree} takes as
    arguments an integer $n$ and list of at least $n$ elements and constructs a
    balanced tree containing the first $n$ elements of the list. The result
    returned by \texttt{partial-tree} is a pair (formed with \texttt{cons})
    whose \texttt{car} is the constructed tree and whose \texttt{cdr} is the
    list of elements not included in the tree.

    \begin{lstlisting}
(define (list->tree elements)
  (car (partial-tree
        elements (length elements))))

(define (partial-tree elts n)
  (if (= n 0)
      (cons '() elts)
      (let ((left-size
             (quotient (- n 1) 2)))
        (let ((left-result
               (partial-tree
                elts left-size)))
          (let ((left-tree
                 (car left-result))
                (non-left-elts
                 (cdr left-result))
                (right-size
                 (- n (+ left-size 1))))
            (let ((this-entry
                   (car non-left-elts))
                  (right-result
                   (partial-tree
                    (cdr non-left-elts)
                    right-size)))
              (let ((right-tree
                     (car right-result))
                    (remaining-elts
                     (cdr right-result)))
                (cons (make-tree this-entry
                                 left-tree
                                 right-tree)
                      remaining-elts))))))))
    \end{lstlisting}

    \begin{enumerate}
        \item Write a short paragraph explaining as clearly as you can how
            \texttt{partial-tree} works. Draw the tree produced by
            \texttt{list->tree} for the list \texttt{(1 3 5 7 9 11)}.
        \item What is the order of growth in the number of steps required by
            \texttt{list->tree} to convert a list of $n$ elements?
    \end{enumerate}
\end{quote}

\begin{enumerate}
    \item \texttt{partial-tree} constructs a tree from a list recursively,
        using the element in the approximate middle of the list as the root and
        trees constructed from the list elements to the left and right of that
        as the left and right branches, respectively. At each level of
        recursion, the number of list elements under consideration is halved.
        When 0 elements are under consideration, an empty tree is produced, so
        1 list element produces a tree with a root and empty branches. By
        keeping track of the elements that haven't been added to the tree yet,
        \texttt{partial-tree} moves through the list from left to right
        (roughly), adding elements to the tree as it goes until there are none
        left to add.

        \begin{allintypewriter}

            \Tree [.5 [.1 \edge[draw=none]; {} 3 ]
                      [.9 7 11 ]]

        \end{allintypewriter}

    \item \texttt{lsit->tree} performs $O(n)$ steps for an $n$-element list. At
        each level of recursion, it performs one $O(1)$ step (constructing the
        tree to return) and two recursive calls with input size $n/2$. This
        means a call with input-size $n$ takes twice as long as a call with
        input size $n/2$, so the time complexity is linear.
\end{enumerate}

\end{document}
